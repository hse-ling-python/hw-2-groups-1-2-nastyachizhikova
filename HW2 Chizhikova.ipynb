{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2. Чижикова Анастасия, БКЛ181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Подготовка. Импортируем нужные модули и читаем текст книги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from pprint import pprint\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import json\n",
    "\n",
    "with open('ubit-peresmeshnika.txt', encoding='utf-8') as f:\n",
    "    book = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обработка с помощью MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6h 51min 59s\n"
     ]
    }
   ],
   "source": [
    "m = Mystem()\n",
    "%time an_text = m.analyze(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NB! я не знаю, почему так много вышло, возможно потому, что компьтер некоторое время был во сне"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сохраняем в json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(an_text, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Обработка с помощью PyMorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Токенизируем текст, удаляем пунктцацию и делаем отдельный список для слов с разметкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "morph = MorphAnalyzer()\n",
    "%time tokens = nltk.word_tokenize(book)\n",
    "words = [w.lower() for w in tokens if w.isalpha()]\n",
    "ana_text = []\n",
    "for word in words:\n",
    "    ana = morph.parse(word)\n",
    "    ana_text.append(ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сохраняем в отдельный список лемму + часть речи (для экономии времени)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for w in ana_text:\n",
    "    a = w[0]\n",
    "    l = [a.normal_form, a.tag.POS]\n",
    "    new_list.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Записываем в файл json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_list, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 4. Ответы на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Считаем количество слов каждой части речи в тексте с помощью Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 20736, 'VERB': 14870, 'NPRO': 10054, 'CONJ': 9673, 'PREP': 8162, 'ADJF': 7007, 'ADVB': 5839, 'PRCL': 5627, 'INFN': 2242, 'ADJS': 718, 'PRED': 564, 'COMP': 462, 'NUMR': 383, 'PRTF': 240, None: 236, 'INTJ': 191, 'GRND': 147, 'PRTS': 132})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "pos_count = collections.Counter()\n",
    "sum_numb = 0\n",
    "for i in new_list:\n",
    "    sum_numb += 1\n",
    "    pos = i[1]\n",
    "    pos_count[pos] += 1\n",
    "print(pos_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Печатаем долю каждой части речи в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0.0027\n",
      "NOUN 0.2376\n",
      "ADJF 0.0803\n",
      "PREP 0.0935\n",
      "PRTF 0.0027\n",
      "NPRO 0.1152\n",
      "CONJ 0.1108\n",
      "ADVB 0.0669\n",
      "VERB 0.1704\n",
      "PRCL 0.0645\n",
      "INFN 0.0257\n",
      "PRTS 0.0015\n",
      "NUMR 0.0044\n",
      "ADJS 0.0082\n",
      "COMP 0.0053\n",
      "PRED 0.0065\n",
      "GRND 0.0017\n",
      "INTJ 0.0022\n"
     ]
    }
   ],
   "source": [
    "for pos in pos_count:\n",
    "    print(pos, round(pos_count[pos]/sum_numb, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Считаем самые популярные глаголы и наречия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_count = collections.Counter()\n",
    "adv_count = collections.Counter()\n",
    "for w in new_list:\n",
    "    if w[1] == 'VERB':\n",
    "        verb_count[w[0]] += 1\n",
    "    elif w[1] == 'ADVB':\n",
    "        adv_count[w[0]] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выводим топ глаголов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сказать 1080\n",
      "быть 1021\n",
      "мочь 339\n",
      "говорить 282\n",
      "стать 246\n",
      "знать 212\n",
      "спросить 204\n",
      "хотеть 184\n",
      "модить 169\n",
      "рэдлить 162\n",
      "идти 136\n",
      "думать 134\n",
      "смотреть 115\n",
      "видеть 113\n",
      "сидеть 110\n",
      "пойти 88\n",
      "выйти 85\n",
      "увидеть 74\n",
      "понять 73\n",
      "взять 67\n"
     ]
    }
   ],
   "source": [
    "top_v = verb_count.most_common()[0:20] \n",
    "for v in top_v:\n",
    "    print(v[0], v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Выводим топ наречий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "потом 221\n",
      "уже 220\n",
      "тут 188\n",
      "очень 166\n",
      "уж 127\n",
      "тогда 122\n",
      "опять 121\n",
      "наверно 118\n",
      "тоже 115\n",
      "совсем 113\n",
      "там 111\n",
      "никогда 106\n",
      "всегда 105\n",
      "почему 102\n",
      "вдруг 99\n",
      "пока 90\n",
      "теперь 88\n",
      "потому 87\n",
      "сейчас 85\n",
      "домой 76\n"
     ]
    }
   ],
   "source": [
    "top_adv = adv_count.most_common()[0:20] \n",
    "for a in top_adv:\n",
    "    print(a[0], a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 5. Биграммы и триграммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Берем только леммы из списка пункта 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for l in new_list:\n",
    "    lemmas.append(l[0])\n",
    "bigrm = nltk.bigrams(lemmas)\n",
    "trigrm = nltk.trigrams(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Считаем частотность би- и триграмм с помощью Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigr_count = collections.Counter()\n",
    "trigr_count = collections.Counter()\n",
    "for bi in bigrm:\n",
    "    bigr_count[bi] += 1\n",
    "for tri in trigrm:\n",
    "    trigr_count[tri] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Берем топ-25 би- и триграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bi = bigr_count.most_common()[0:25]\n",
    "top_tri = trigr_count.most_common()[0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Топ-25 самых частотных биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('я', 'не')\n",
      "('мисс', 'модить')\n",
      "('сказать', 'он')\n",
      "('и', 'не')\n",
      "('мы', 'с')\n",
      "('у', 'он')\n",
      "('и', 'я')\n",
      "('сказать', 'аттикус')\n",
      "('он', 'не')\n",
      "('сказать', 'джим')\n",
      "('не', 'мочь')\n",
      "('сказать', 'я')\n",
      "('с', 'джим')\n",
      "('он', 'быть')\n",
      "('мистер', 'тейт')\n",
      "('тётя', 'александр')\n",
      "('у', 'мы')\n",
      "('что', 'он')\n",
      "('весь', 'равно')\n",
      "('он', 'и')\n",
      "('не', 'знать')\n",
      "('я', 'и')\n",
      "('мистер', 'финч')\n",
      "('судья', 'тейлор')\n",
      "('что', 'я')\n"
     ]
    }
   ],
   "source": [
    "for t in top_bi:\n",
    "    print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Топ-25 самых частотных триграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('мы', 'с', 'джим')\n",
      "('у', 'он', 'быть')\n",
      "('мисс', 'стивеня', 'кроуфорд')\n",
      "('глава', 'глава', 'глава')\n",
      "('сказать', 'мисс', 'модить')\n",
      "('посмотреть', 'на', 'я')\n",
      "('я', 'не', 'мочь')\n",
      "('у', 'мы', 'в')\n",
      "('я', 'не', 'знать')\n",
      "('из', 'весь', 'сила')\n",
      "('мисс', 'модить', 'и')\n",
      "('мистер', 'гек', 'тейт')\n",
      "('не', 'знать', 'что')\n",
      "('ходить', 'в', 'школа')\n",
      "('я', 'никогда', 'не')\n",
      "('сказать', 'он', 'я')\n",
      "('на', 'этот', 'раз')\n",
      "('я', 'так', 'и')\n",
      "('на', 'я', 'и')\n",
      "('у', 'я', 'быть')\n",
      "('терпеть', 'не', 'мочь')\n",
      "('весь', 'равно', 'что')\n",
      "('сказать', 'тётя', 'александр')\n",
      "('с', 'тот', 'пора')\n",
      "('мы', 'с', 'диллом')\n"
     ]
    }
   ],
   "source": [
    "for t in top_tri:\n",
    "    print(t[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
